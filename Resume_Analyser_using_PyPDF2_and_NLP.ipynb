{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBNWHTqgRwQGETUdBkBRVh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aman78695/Resume_Analyser_nlp/blob/main/Resume_Analyser_using_PyPDF2_and_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqdGoYg__-3B",
        "outputId": "7c542427-271f-4c5a-ec3c-c13793e9197e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "#installing pdf reader PyPDF2\n",
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2"
      ],
      "metadata": {
        "id": "FL8By7sCAVlp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# - **Read Resume**"
      ],
      "metadata": {
        "id": "Yb2UE3DfD6nG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resume_file_Path='/content/Md_Amanatullah_Resume_DS.pdf'\n",
        "filehandle=open(resume_file_Path,'rb')"
      ],
      "metadata": {
        "id": "RUmzmsiNEGPD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "\n",
        "file_path = \"/content/Md_Amanatullah_Resume_DS.pdf\"\n",
        "\n",
        "# Open the PDF file\n",
        "with open(file_path, 'rb') as file:\n",
        "    reader = PyPDF2.PdfReader(file)\n",
        "\n",
        "    text = \"\"  # Variable to store the extracted text\n",
        "\n",
        "    # Loop through each page\n",
        "    for page in reader.pages:\n",
        "        # Extract text from the current page\n",
        "        page_text = page.extract_text()\n",
        "\n",
        "        # Append the extracted text to the overall text\n",
        "        text += page_text\n",
        "\n",
        "# Print the extracted text from all pages\n",
        "print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSS39rBYFbkJ",
        "outputId": "737889b8-5c1d-4271-9ea4-1b2b3202e2ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page 1 of 2 \n",
            "PROJECTS \n",
            "Email Spam Classiﬁcation \n",
            "CodersCave Internship Project.\n",
            " \n",
            " \n",
            "05/2023 - 06/2023\n",
            ", \n",
            " \n",
            "EDA conducted on spam and ham emails, analyzing counts and visualizing diﬀerences\n",
            "with\n",
            " histograms and pairwise plots. \n",
            "Preprocessing included \n",
            "lowercase conversion\n",
            ", word \n",
            "tokenization, stopword and\n",
            "punctuation removal, \n",
            "and\n",
            " lemmatization\n",
            ". \n",
            "Achieved\n",
            " 97% accuracy \n",
            "and \n",
            "91% precision\n",
            " for \n",
            "SVM\n",
            " in training and evaluating\n",
            "multiple ML models (\n",
            "Naive Bayes, SVM, Random Forest\n",
            "). \n",
            "Cardiovascular Risk Prediction \n",
            "AlmaBetter Veriﬁed Project.\n",
            " \n",
            " \n",
            "01/2023 - 02/2023\n",
            ", \n",
            " \n",
            "Developed \n",
            "supervised ML\n",
            " model to predict whether the patient has 10 year risk of\n",
            "future Coronary Heart Disease. \n",
            "Imbalances in the datasets was handeled using \n",
            "SMOTE.\n",
            " \n",
            "Achieved \n",
            "84% accuracy\n",
            " with performance metrics including \n",
            "confusion matrix,\n",
            "precision, recall, F-score, and AUC-ROC. \n",
            "Credit Card Churn Prediction \n",
            "CampusX Veriﬁed Project.\n",
            " \n",
            " \n",
            "12/2022 - 01/2023\n",
            ", \n",
            " \n",
            "The project focused on predicting customer churn in credit card usage using\n",
            "Artiﬁcial Neural Networks (ANN) with TensorFlow and Keras.\n",
            " \n",
            "Project predicts credit card churn, empowering proactive customer retention for\n",
            "businesses. \n",
            "Retail Sales Prediction \n",
            "AlmaBetter Veriﬁed Project.\n",
            " \n",
            " \n",
            "11/2022 - 12/2022\n",
            ", \n",
            " \n",
            "The project involved utilizing\n",
            " NumPy, Pandas, Matplotlib, Seaborn, and Scikit-Learn\n",
            "for data manipulation, handling missing values, EDA. \n",
            "Conclusion: \n",
            "The model explained 95.5878% \n",
            "of the variations and provided good\n",
            "sales predictions. \n",
            "Exploratory Data Analysis (EDA) of Google Play Store\n",
            "Dataset \n",
            "CodersCave Internship Project.\n",
            " \n",
            " \n",
            "05/2023 - 06/2023\n",
            ", \n",
            " \n",
            "Performed thorough\n",
            " EDA\n",
            " on the Google Play Store dataset to gain insights into app\n",
            "characteristics and user preferences. \n",
            "Utilized Python and popular libraries like \n",
            "NumPy, Pandas, Matplotlib, and Seaborn\n",
            "for data analysis \n",
            "and visualization. \n",
            "Explored app categories, content ratings, and highlighted key trends to provide\n",
            "strategic recommendations for \n",
            "app development and marketing strategies.\n",
            " \n",
            "WORK EXPERIENCE \n",
            "Data Scientist Intern \n",
            "CodersCave.\n",
            " \n",
            " \n",
            "05/2023 - 06/2023\n",
            ", \n",
            " \n",
            "Chennai \n",
            "Utilized \n",
            "NLP techniques\n",
            " to process and analyze\n",
            "textual data. \n",
            "Conducted detailed \n",
            "EDA\n",
            " on Google Play Store\n",
            "apps, extracting insights through\n",
            " statistical\n",
            "analysis\n",
            " and\n",
            " visualization\n",
            ". \n",
            "Experienced in deploying machine learning models\n",
            "using \n",
            "PyCharm,Streamlit,Flask,API.\n",
            " \n",
            "Data Scientist Intern \n",
            "Code Cause.\n",
            " \n",
            " \n",
            "04/2023 - 05/2023\n",
            ", \n",
            " \n",
            "Implemented a deep learning project using\n",
            "Python, Keras, and OpenCV \n",
            "to accurately\n",
            " predict\n",
            "age, gender, and emotion from images.\n",
            " \n",
            "Showcased its\n",
            " real-world application potential in\n",
            "areas such as HR, marketing, and customer\n",
            "analytics. \n",
            "Developed a \n",
            "deep learning model using Keras\n",
            "and OpenCV to accurately detect brain tumors\n",
            "from MRI images,\n",
            " showcasing its potential in\n",
            "medical diagnostics. \n",
            "Implemented techniques such as \n",
            "convolutional\n",
            "neural networks, data augmentation, and model\n",
            "training\n",
            " to achieve accurate classiﬁcation results. \n",
            "TRAINING EXPERIENCE\n",
            "Data Science Trainee \n",
            "AlmaBetter. \n",
            "06/2022 - Present\n",
            ", \n",
            " \n",
            "Bangalore \n",
            "Developed predictive models using \n",
            "Linear\n",
            "Regression\n",
            ", \n",
            "Logistic Regression, Decision Tree,\n",
            "KNN, SVM, PCA, Naive Bayes, Bagging, Boosting,\n",
            "and\n",
            " Clustering\n",
            " in Python. \n",
            "Constructed\n",
            " Deep Learning and NLP models\n",
            " and\n",
            "scalable machine learning systems. \n",
            "Leveraged \n",
            "ChatGPT and GPT-4\n",
            " to automate\n",
            "coding tasks, performed code debugging, and\n",
            "added new features to the code. \n",
            "Tasks/Achievements \n",
            "Tasks/Achievements \n",
            "Tasks/Achievements \n",
            "Tasks/Achievements \n",
            "Tasks/Achievements \n",
            "Tasks/Achievements \n",
            "Tasks/Achievements \n",
            "Achievements/Tasks \n",
            "amanatulla1606@gmail.com \n",
            "8789434226 \n",
            "linkedin.com/in/md-amanatullah-8b7a58231 \n",
            "github.com/Aman78695?tab=repositories \n",
            "Md Amanatullah \n",
            "As an ambitious Data Scientist, I bring a diverse skill set and a passion for leveraging\n",
            "data to drive meaningful insights. With a strong foundation in Python,\n",
            "SQL,Tableau,PowerBI,Excel, Machine Learning, Deep Learning, Natural Language\n",
            "Processing, and Artiﬁcial Intelligence, I am equipped with the tools to tackle complex\n",
            "analytical challenges. Page 2 of 2 \n",
            "PROJECTS \n",
            "Flight Dashboard \n",
            "CampusX Veriﬁed Project.\n",
            " \n",
            " \n",
            "02/2023 - 03/2023\n",
            ", \n",
            " \n",
            "Developed a Flight Dashboard utilizing \n",
            "Streamlit, Python, and SQL\n",
            " to provide users\n",
            "with an interactive interface for exploring ﬂight information. \n",
            "Dashboard allows users to search for ﬂights based on source and destination,\n",
            "retrieve data from a \n",
            "MySQL database, and visualize ﬂight analytics using Plotly. \n",
            "Key features include a\n",
            " dynamic selection menu\n",
            ", real-time data retrieval, and a \n",
            "pie\n",
            "chart displaying airline frequency.\n",
            " \n",
            "Online Retail Customer Segmentation \n",
            "AlmaBetter Veriﬁed Project.\n",
            " \n",
            " \n",
            "10/2022 - 11/2022\n",
            ", \n",
            " \n",
            "Utilized \n",
            "RFM analysis \n",
            "to segment online retail customers based on their purchasing\n",
            "behavior, considering factors such as \n",
            "recency of purchase, frequency of purchase,\n",
            "and monetary value.\n",
            " \n",
            "Conducted EDA identiﬁed trends for\n",
            " segmentation process\n",
            ", \n",
            "implemented\n",
            "personalized marketing, drove customer engagement, retention, and business\n",
            "growth. \n",
            "HR Analytics Tableau Dashboard \n",
            "AlmaBetter Veriﬁed Project.\n",
            " \n",
            " \n",
            "05/2023 - 06/2023\n",
            ", \n",
            " \n",
            "Developed a comprehensive\n",
            " HR Analytics Tableau dashboard \n",
            "to provide actionable\n",
            "insights into employee data and facilitate informed decision-making. \n",
            "Visualized key\n",
            " HR metrics\n",
            " including \n",
            "employee demographics, attrition rates, and\n",
            "departmental distributions. \n",
            "Interactive dashboard enabled stakeholders to monitor workforce trends, identify\n",
            "areas for improvement, and \n",
            "make data-driven HR decisions. \n",
            "Superstore Sales Analysis PowerBI Dashboard \n",
            "AlmaBetter Veriﬁed Project.\n",
            " \n",
            " \n",
            "05/2023 - 06/2023\n",
            ", \n",
            " \n",
            "Created an\n",
            " interactive PowerBI dashboard\n",
            ", to provide comprehensive\n",
            " insights into\n",
            "sales, proﬁt, discount, and quantity metrics through cards. \n",
            "Utilized charts for proﬁt analysis \n",
            ",line charts and employed matrix hierarchy and\n",
            "slicers \n",
            "for sales trends\n",
            ", incorporating data exploration and ﬁltering capabilities for\n",
            "enhanced visualization. \n",
            "Dashhboard enabled stakeholders to gain valuable insights into sales performance\n",
            "and \n",
            "make data-driven decisions for optimizing business operations. \n",
            "TECHNICAL SKILLS \n",
            "Expertise in Language and Tools \n",
            "Python 4.5 | DSA | SQL 4.5 | Excel 4.5 | PowerBI 4.5 | \n",
            "Matplotlib | Seaborn | Plotly |\n",
            "Tableau | Git and GitHub | HTML 5 | CSS 3 | Tensorﬂow 2.12.0 | Keras 2.12.0 | Linux | Scikit\n",
            "Learn 1.2.2 | Flask | API | Streamlit. \n",
            "Platform \n",
            "Jupyter | Google Colab | Pycharm | VS Studio | PostgreSQL | MySQL \n",
            "ML Framework \n",
            "ML | DL(ANN,CNN,RNN) | NLP \n",
            "(AlexNet,ResNet-\n",
            "50,GoogleNet,VGG16,BERT,SPAcy,TEXTHERO,GPT2,RoBERTa,CodeBERT,NLTK,Spacy,XLN\n",
            "et,Huggingface, transformers) \n",
            "ACHIEVEMENTS \n",
            "Gold Badge in Python and Sql\n",
            " (12/2022)\n",
            " \n",
            " \n",
            "Hackerrank \n",
            "PUBLICATIONS \n",
            "Blog \n",
            "Unraveling the Power of Forward\n",
            "Propagation: Predicting Outputs in Neural\n",
            "Networks.\n",
            " \n",
            " \n",
            "23-05-2023 \n",
            "Medium \n",
            "Blog \n",
            "When Normal Just Won’t Cut It:\n",
            "Understanding and Utilizing Non Gaussian\n",
            "Distributions.\n",
            " \n",
            " \n",
            "15-06-2023 \n",
            "Medium \n",
            "Blog \n",
            "Backpropagation Algorithm in Neural\n",
            "Networks: The What, How, and Why?\n",
            " \n",
            " \n",
            "02-06-2023 \n",
            "Medium \n",
            "EDUCATION \n",
            "B.Tech(Computer Science) \n",
            "Kalinga University,Raipur\n",
            " \n",
            " \n",
            "2015-2019 || CGPA- 7.8 \n",
            "B.Sc.(Mathematics) \n",
            "Shobhit University,Meerut\n",
            " \n",
            " \n",
            "2011-2014  ||  CGPA-6.67 \n",
            "Tasks/Achievements \n",
            "Tasks/Achievements \n",
            "Tasks/Achievements \n",
            "Tasks/Achievements \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# - Read Job Description"
      ],
      "metadata": {
        "id": "p2BrYiqfwnV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "\n",
        "file_path1 = \"/content/Data_Scientist_Job_Description.pdf\"\n",
        "\n",
        "# Open the PDF file\n",
        "with open(file_path1, 'rb') as file:\n",
        "    reader = PyPDF2.PdfReader(file)\n",
        "\n",
        "    text1 = \"\"  # Variable to store the extracted text\n",
        "\n",
        "    # Loop through each page\n",
        "    for page in reader.pages:\n",
        "        # Extract text from the current page\n",
        "        page_text = page.extract_text()\n",
        "\n",
        "        # Append the extracted text to the overall text\n",
        "        text1 += page_text\n",
        "\n",
        "# Print the extracted text from all pages\n",
        "print(text1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUC9W3XWwm0u",
        "outputId": "00a48b00-bcb0-4adb-e2f3-7895ecd9663c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Scientist Job Description Template\n",
            "Here’s an example of a data scientist job description template that you can adapt for your\n",
            "team’s hiring needs. Feel free to add or remove the amount of responsibilities, experience,\n",
            "and qualifications needed based on the seniority of the role. Enjoy!\n",
            "— The DataCamp Team\n",
            "Data Scientist\n",
            "Description\n",
            "As a data scientist at\n",
            "[add company name]\n",
            ", you will\n",
            "drive real-world impact by applying\n",
            "innovative data-driven technology to our ever-growing dataset.\n",
            "You will be responsible for the end-to-end data science project lifecycle, starting from\n",
            "problem scoping to machine learning systems deployment and maintenance.\n",
            "[Add a\n",
            "thorough description of the different types of projects and data sources, and outline the\n",
            "specific deliverables a candidate is expected to deliver.]\n",
            "The ideal candidate possesses a strong analytical ability to solve complex problems with\n",
            "data.\n",
            "Responsibilities\n",
            "●\n",
            "Work with large datasets on data extraction, cleaning, exploration, analysis, and\n",
            "presentation.\n",
            "●\n",
            "Formulate data science solutions to business problems by collaborating with business\n",
            "and product teams.\n",
            "●\n",
            "Design and implement algorithms to solve a wide array of challenging problems with\n",
            "analytics and statistical approaches built on high-volume, high-dimensional\n",
            "datasets.\n",
            "●\n",
            "Deploy, test, validate, and maintain machine learning models in production by\n",
            "collaborating with data engineers and machine learning engineers.\n",
            "●\n",
            "Perform extract, transform, load operations from data sources for modeling purposes.\n",
            "●\n",
            "Design, perform and analyze A/B tests.\n",
            "●\n",
            "[Remove or add problems relevant to this specific job title]\n",
            "Scope and work on\n",
            "problems such as:\n",
            "○\n",
            "Provide the most relevant recommendations during check-out.\n",
            "[Insert website here]\n",
            "[Insert logo here]\n",
            "○\n",
            "Detect fraudulent users with sparse, high-dimensional data.\n",
            "○\n",
            "Generate credit scores for customers.\n",
            "○\n",
            "Predict the arrival time of a parcel based on traffic conditions.\n",
            "○\n",
            "Use natural language processing for sentiment analysis, message\n",
            "auto-completion, or search query correction.\n",
            "●\n",
            "[If necessary, add additional job requirements]\n",
            "Experience\n",
            "●\n",
            "Bachelor's degree or higher, or equivalent practical experience.\n",
            "●\n",
            "[If necessary, add X+ years of relevant analytics experience]\n",
            "Minimum Qualifications\n",
            "●\n",
            "Solid knowledge of statistical methods and machine learning fundamentals.\n",
            "●\n",
            "Strong proficiency in Python, R.\n",
            "●\n",
            "Strong proficiency in SQL.\n",
            "●\n",
            "Hands-on experience with data analytics and classical machine learning tools\n",
            "(e.g.\n",
            "pandas, NumPy, scikit-learn)\n",
            "and deep learning frameworks\n",
            "(e.g. Tensorflow, Pytorch)\n",
            ".\n",
            "●\n",
            "[Make sure to mention any other technologies relevant to your project.]\n",
            "●\n",
            "Excellent written and verbal communication skills.\n",
            "●\n",
            "Excellent stakeholder management skills.\n",
            "●\n",
            "Ability to tell stories with data, and deliver data-driven insights to a wide range of\n",
            "audiences.\n",
            "What will make you stand out\n",
            "●\n",
            "Experience in production software engineering routines\n",
            "(e.g. Git versioning,\n",
            "Continuous Integration/Continuous Deployment)\n",
            ".\n",
            "●\n",
            "Familiarity or experience with working on large data sets and distributed computing\n",
            "(e.g. Hive, Hadoop, Spark, Presto, MapReduce).\n",
            "●\n",
            "Working knowledge of Cloud-based solutions\n",
            "(e.g. AWS,\n",
            "Azure, GCP).\n",
            "●\n",
            "[If necessary, add additional preferred qualification]\n",
            "[Insert website here]\n",
            "[Insert logo here]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content=[text,text1]"
      ],
      "metadata": {
        "id": "flPhCdAbxrAi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer()\n",
        "metrix=cv.fit_transform(content)"
      ],
      "metadata": {
        "id": "Fp8_LJlpxuoM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "similarity_matrix=cosine_similarity(metrix)"
      ],
      "metadata": {
        "id": "Vj5MIdrYyLJK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0Vkp_f3yex6",
        "outputId": "a4e35a34-d614-4c77-e9e3-ce6aeb72ce62"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.58664412],\n",
              "       [0.58664412, 1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}